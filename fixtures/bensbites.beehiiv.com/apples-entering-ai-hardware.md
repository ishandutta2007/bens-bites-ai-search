# Apple's entering into AI with hardware.

Apple has released new Macs powered by M3 chips, showing they are[embracing AI through custom hardware.](https://www.youtube.com/watch?v=ctkW3V0Mh-k\&utm_source=bensbites\&utm_medium=referral\&utm_campaign=apple-s-entering-into-ai-with-hardware) The M3 Max chip targets AI/ML developers with its powerful GPU stack.

## What’s going on here?

Apple’s news M3 chips have new GPUs optimized for AI, up to 2.5x faster than M1.

![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/5c9d797f-92b1-499d-a36e-fddd88adb861/image.png)

## What does that mean?

The new M3 chips have a new GPU architecture with a feature Apple calls dynamic caching. Dynamic caching allocates GPU memory adaptively in real-time, increasing the utilization of the GPU. The new neural engine is 60% faster, speeding up ML.

The M3 Max has a 16-core CPU and 40-core GPU supporting 128GB of unified memory. Apple claims that’ll allow developers to work with models with billions of parameters.

Apple is keeping pace with AI-focused offerings from rivals like Qualcomm. Qualcomm made a similar claim this month with their Snapdragon X Elite of being able to run a 13B model on-device.

## Why should I care?

If you use graphics/ML apps, the new Macs will bring meaningful speed improvements. If you’re a developer, Apple's platform is now more compelling for generative AI projects needing local compute.

And there’s the obvious answer to why should you care: because it’s APPLE.
