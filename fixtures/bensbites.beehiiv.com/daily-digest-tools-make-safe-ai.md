# Daily Digest: Tools to make safe AI

### PLUS: Smaller models are on the rise.

[Sign up](https://www.bensbites.co/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)|[Advertise](https://sponsor.bensbites.co/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)|[Ben‚Äôs Bites News](https://news.bensbites.co/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)\
Daily Digest #302

Hello folks, here‚Äôs what we have today;

###### **PICKS**

1. I wrote a post on ‚Äò[How to build an AI-powered company](https://bensbites.beehiiv.com/p/build-aipowered-company)‚Äô. These are some of the tools I‚Äôd use (and why) if I were starting something new today. And you don‚Äôt need to know how to code.

2. [Meta is announcing Purple Llama](https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai), an open-source project to provide**trust and safety tools**and evaluations for developing responsible generative AI models. It is open-sourcing tools and benchmarks focused on**cybersecurity**and**content safety**for generative AI.üçø[Our Summary](https://bensbites.beehiiv.com/p/purple-llama-meta-evals-models-open-source-safety)(also below)

3. [Anthropic has developed a new method](https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)to**measure and reduce discrimination**in language model decisions for areas like loans, jobs, insurance claims etc. The solution?**Just tell the AI to be nice.**They also release a[dataset](https://huggingface.co/datasets/Anthropic/discrim-eval?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)covering**70 diverse scenarios**including loan applications, visa approvals, and security clearances.üçø[Our Summary](https://bensbites.beehiiv.com/p/solve-ai-discrimination)(also below)

4. [Stability AI introduces StableLM Zephyr 3B](https://stability.ai/news/stablelm-zephyr-3b-stability-llm?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai), a new 3 billion parameter AI assistant model from StableLM designed to provide\*\*accurate and fast text generation on regular hardware.\*\*üçø[Our Summary](https://bensbites.beehiiv.com/p/stability-ais-new-model-stablelm-zephyr-3b-can-run-smartphones)(also below)

ps: Adobe is working on a Chat with PDF tool[in beta.](https://x.com/scottbelsky/status/1732813389292851513?s=20\&utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)

###### **TOP TOOLS**

- [Strut AI](https://strut.so/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)- All-in-one AI workspace designed for**writers**.

- [Openlayer](https://www.openlayer.com/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)- Slack or email alerts for when your**AI fails.**

- [VEED Captions App](https://apps.apple.com/us/app/veed-captions-for-videos/id1634439688?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)- The simplest way to create engaging**short-form videos.**

- [Pearl by Meta](https://pearlagent.github.io/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)- Production-ready reinforcement learning**AI agent library.**

- [Ello](https://www.helloello.com/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)- AI**reading coach**to make kids fall in love with books.

- Open source[function calling](https://github.com/stellar-amenities/assistants/tree/main/examples/hello-world-anthropic-function-calling?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)for Anthropic, or**any other LLM.**

[View more ‚Üí](https://news.bensbites.co/tags/show?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)

###### **NEWS**

- An opinionated guide to\*\*[which AI to use.](https://www.oneusefulthing.org/p/an-opinionated-guide-to-which-ai?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)\*\*

- Using ChatGPT for\*\*[writing and recommending books.](https://www.youtube.com/watch?app=desktop\&v=rxG-7a-gmIs)\*\*

- Applications open for the\*\*[next Betaworks camp](https://render.betaworks.com/apply-to-ai-camp-agents-the-10th-accelerator-program-from-betaworks-starting-feb-2024-37f0c70678db?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)\*\*focused on AI agents.

- What does physics have to say about AI risk? Focusing on\*\*[physically possible scenarios](https://www.sequoiacap.com/article/black-holes-perspective/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)\*\*\*\*.\*\*

- **[MatterGen by Microsoft](https://arxiv.org/abs/2312.03687?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)**- Increasing the rate at which we design materials with desired properties.

- Stability AI and Intel are building a\*\*[new AI supercomputer.](https://stability.ai/news/building-new-ai-supercomputer?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)\*\*

- AI has killed\*\*[software switching costs](https://www.fillout.com/blog/ai-switching-costs?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)\*\*\*\*.\*\*

- \*\*[Helen Toner rejects safety issues](https://www.wsj.com/tech/ai/helen-toner-openai-board-2e4031ef?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)\*\*as the cause behind Sam Altman‚Äôs firing. However, she adds that dismissing Sam (based on the lack of trust) was consistent with the OpenAI board‚Äôs duty.

- \*\*[AMD launches Instinct MI300X](https://www.tomshardware.com/pc-components/cpus/amd-unveils-instinct-mi300x-gpu-and-mi300a-apu-claims-up-to-16x-lead-over-nvidias-competing-gpus?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)\*\*and MI300A AI accelerators.

[View more ‚Üí](https://news.bensbites.co/tags/news/trending?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)

**Unclassifieds**- short, sponsored links

- [Founder University](https://founder.university/bens-bites?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)- Build & launch your idea in 12 weeks.**We invest $25k into 20-30 teams.**[Apply Today](https://founder.university/bens-bites?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai).

###### **QUICK BITES**

[Meta is announcing Purple Llama](https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai), an open source project to provide trust and safety tools and evaluations for developing responsible generative AI models.

**What is going on here?**

Meta is open-sourcing tools and benchmarks focused on cybersecurity and content safety for generative AI to enable developers to build responsibly.

![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/4f84e0f4-5fc2-4b00-99b3-c38778928185/image.png?t=1702036142)

**What does this mean?**

To start Purple Llama, Meta is releasing CyberSec Eval, a set of cybersecurity benchmarks for evaluating potential risks in language models. You can test your LLM‚Äôs tendency to recommend insecure code and comply with malicious requests with CyberSec Eval.

Additionally, Meta is providing Llama Guard, a content safety classifier to filter risky outputs. It is a pre-trained model to help defend against generating potentially risky outputs.

**Why should I care?**

Open-source models are great. At the same time, open-source eval systems are also needed. Purple Llama is an umbrella project for such efforts. Even if you want to write your own evals, having a base set to rely on is great. The best way to ensure people follow safety standards for their deployments is by making it easier to do so.

[*Share this story*](https://bensbites.beehiiv.com/p/purple-llama-meta-evals-models-open-source-safety)

###### **QUICK BITES**

Anthropic has developed a new method to[measure and reduce discrimination](https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)in language model decisions for areas like loans, jobs, insurance claims etc. They release a[dataset](https://huggingface.co/datasets/Anthropic/discrim-eval?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)covering 70 diverse scenarios including loan applications, visa approvals, and security clearances.

**What is going on here?**

Simple techniques like adding ‚Äúdiscrimination is illegal‚Äù reduce discriminatory language model outputs for high-stakes decisions.

![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/d2a1bf8b-92da-4f26-b4c4-4a29ef693a14/image.png?t=1702034410)

**What does this mean?**

Anthropic created a 3-step process to systematically evaluate discrimination in language models.

- Creating diverse decision scenarios like job offers or insurance claims where models might be used.

- Creating question templates with demographic info as variables to measure bias.

- Modifying demographics like age, race and gender while keeping other info equal.

The result highlighted both, negative discrimination and positive discrimination. Anthropic is also releasing the[dataset used for this evaluation](https://huggingface.co/datasets/Anthropic/discrim-eval?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai).

The study also tested various prompting strategies to mitigate discrimination. Effective options included asking models to ensure unbiased answers, provide rationales without stereotypes, and answer questions without considering demographic data. Two simple prompts nearly eliminated bias: stating discrimination is illegal and instructing the model to ignore demographic info.

**Why should I care?**

As language models spread to high-stakes decisions, developers and policymakers need tools to assess and address risks like discrimination. Anthropic's public release of their evaluation methodology allows wider testing for biases.

Their findings also demonstrate prompting as an accessible "dial" to control problematic outputs. Persuade the AI like you persuade a human.

[*Share this story*](https://bensbites.beehiiv.com/p/solve-ai-discrimination)

###### **QUICK BITES**

[Stability AI introduces StableLM Zephyr 3B](https://stability.ai/news/stablelm-zephyr-3b-stability-llm?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai), a new 3 billion parameter AI assistant model from StableLM designed to provide accurate and fast text generation on regular hardware.

**What is going on here?**

StableLM Zephyr 3B brings the power of large language models to more devices.

![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/e8efdb07-a815-4f6b-9851-37de11bdaddc/image.png?t=1702037697)

**What does this mean?**

Stable LM Zephyr 3B is built by fine-tuning on diverse datasets to compress more capability in smaller size. Zephyr 3B matches or exceeds the performance of multiple 7B models on instruction following, QA tasks, and text generation quality. The magic of a small 3B model is that users can get responsiveness and accuracy without expensive hardware.

Zephyr is being released under a[non-commercial license](https://huggingface.co/stabilityai/stablelm-zephyr-3b/raw/main/LICENSE?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)that permits non-commercial use.

- Download the model weights[here.](https://huggingface.co/stabilityai/stable-zephyr-3b-dpo?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai)

- Example notebook to optimize speed for this model[here](https://github.com/eaidova/openvino_notebooks/blob/ea/stateful_chatbot/notebooks/273-stable-zephyr-3b-chatbot/273-stable-zephyr-3b-chatbot.ipynb?utm_source=bensbites\&utm_medium=referral\&utm_campaign=daily-digest-tools-to-make-safe-ai).

**Why should I care?**

Smaller high-performing models like Zephyr 3B mean you can try building capable AI tools for more average hardware setups. Products powered by Zephyr 3B could work well on phones, tablets, laptops etc. I‚Äôm interested to see how people create tiny personal tools with Zephyr.

[*Share this story*](https://bensbites.beehiiv.com/p/stability-ais-new-model-stablelm-zephyr-3b-can-run-smartphones)

### Ben‚Äôs Bites Insights

We have 2 databases that are updated daily which you can access by sharing Ben‚Äôs Bites using the link below;

- **All 10k+ links**we‚Äôve covered, easily filterable (1 referral)

- **6k+ AI company funding rounds**from Jan 2022, including investors, amounts, stage etc (3 referrals)
