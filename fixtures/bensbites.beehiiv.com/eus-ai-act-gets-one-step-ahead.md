# EU's AI act gets one step ahead.

The EU has reached a provisional agreement on its [Artificial Intelligence Act](https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai?utm_source=bensbites\&utm_medium=referral\&utm_campaign=eu-s-ai-act-gets-one-step-ahead) to ensure AI systems are safe and respect fundamental rights while supporting innovation.

## What's going on here?

The Act adds bans on multiple AI applications and systems based on their level of risk, but again with vague and wide statements.

![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/00f5c287-a8ad-48f1-b7b1-68cf5379fa4d/image.png?t=1702288951)

## What does this mean?

The Act bans biometric categorisation, scraping facial images, emotion recognition, and social scoring systems in specific situations. The weirdest ban is on AI systems that manipulate human behaviour to circumvent their free will. These banned use cases are allowed in situations like finding victims, and criminals and preventing terrorists. In simple words, whenever the government wants.

For high-risk AI systems, companies must conduct assessments and provide transparency. This includes areas like banking and insurance. Citizens can file complaints about systems impacting their rights and receive explanations of decisions. Fines for non-compliance range from millions or a percentage of global turnover depending on the violation and company size.

## Why should I care?

There’s still time for it to become a law but we’re way deep into the process. Laws once made usually expand to cover more and more space, they are rarely taken back. AI risks are real, but the law should focus on the risky applications of AI. This proposal does it sometimes but other times flickers into vague statements.
