# Fresh from OpenAI: New embedding models and cost savings

[Fresh from OpenAI](https://openai.com/blog/new-embedding-models-and-api-updates?utm_source=bensbites\&utm_medium=referral\&utm_campaign=fresh-from-openai-new-embedding-models-and-cost-savings): They’ve launched two spanking new embedding models, spiced up GPT-4 Turbo, and made GPT-3.5 Turbo more wallet-friendly. There’s more on moderation and API usage below.

## What’s going on here?

OpenAI's latest drop is all about giving devs more bang for their buck and some nifty new toys to play with.

![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/1609695f-e598-451b-8b13-61e2fe0caf50/image.png?t=1706273527)

## What does this mean?

The new embedding models: We've got a small one (text-embedding-3-small) that's leaner in price (we're talking a 5X price drop)and a large one (text-embedding-3-large) that’s the new heavyweight champ.

GPT-3.5 Turbo is about to get cheaper, slashing input costs by 50% and output by 25%. GPT-4 Turbo's new preview model promises to end those frustrating 'lazy' responses (coders unite) and smooth over language hiccups for non-English tasks.

The moderation model got an upgrade, making it tougher on potentially harmful content. We are also getting API key-level metrics in the usage dashboard for better tracking and the ability to assign permissions to API keys.

## Why should I care?

This update is a toolkit upgrade. And a much-needed one at that. The old embedding models were still the leader but other companies had started to catch up. RAG and chat with data apps are gonna become cool again.

And, everyone hates lazy chat, so let’s see how active the updated version is.
