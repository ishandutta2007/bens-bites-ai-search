# Frontier Model Forum

**[Frontier Model Forum updates](https://openai.com/blog/frontier-model-forum-updates?utm_source=bensbites\&utm_medium=referral\&utm_campaign=frontier-model-forum)** - Together with Anthropic, Google, and Microsoft, OpenAI announced the new Executive Director of the Frontier Model Forum and a new $10 million AI Safety Fund.

## What's going on here?

Major AI companies are banding together to promote AI safety research and practices.

## What does this mean?

The Frontier Model Forum was formed by leading AI companies to advance responsible development of powerful AI models. They have now appointed Chris Meserole, who has extensive experience in AI policy, as Executive Director. The companies, along with philanthropic donors, are also committing over $10 million to launch an AI Safety Fund that will support independent research into AI safety techniques like red teaming. The Forum has published its first technical update on red teaming definitions and case studies to establish a common baseline. They aim to share knowledge and best practices on safely building, testing and evaluating the most capable AI systems.

## Why should I care?

As AI becomes more powerful, ensuring it is developed safely and ethically is crucial. This collaboration between industry leaders shows commitment to making AI trustworthy by investing in safety research and bringing in outside experts. While AI promises immense benefits, its risks need to be addressed. Initiatives like the Frontier Model Forum and AI Safety Fund are important steps toward responsible AI innovation that considers not just capabilities, but consequences. Supporting independent scrutiny and high safety standards will lead to AI that works for people.
