# OpenAI hustles to beat Google to launch ‘Multimodal’ LLM

[OpenAI hustles to beat Google to launch ‘Multimodal’ LLM](https://www.theinformation.com/articles/openai-hustles-to-beat-google-to-launch-multimodal-llm?utm_source=bensbites\&utm_medium=referral\&utm_campaign=openai-hustles-to-beat-google-to-launch-multimodal-llm), as reported by The Information. With all the reports of Gemini being released soon and potentially better than GPT-4, Open AI is trying to keep its lead intact. The multimodal features will be launched under the name **“GPT-vision.”** Also, they are training a **multimodal LLM from scratch codenamed Gobi.**

## What’s going on here?

Google and OpenAI are competing to release the next generation of AI models that can understand both text and images.

## What does this mean?

These new “multimodal” models will be able to generate code from website sketches and analyze visual data, among other capabilities. Google is close to releasing its Gemini model, while OpenAI is rushing to add multimodal features to GPT-4. There are concerns around potential misuse, but both companies are taking steps to ensure responsible development. This race parallels big tech platform competitions like iPhone vs Android.

## Why should I care?

These more advanced AI systems will likely enable new applications and expand what computers can do. However, their capabilities also raise important questions around ethics, bias, and proper oversight that impact society. Following this innovation race helps understand the pace of AI progress and emergence of new powers that could affect daily life.
