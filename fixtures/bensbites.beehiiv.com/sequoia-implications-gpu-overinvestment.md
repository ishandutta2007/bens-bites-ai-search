# Sequoia: Implications of GPU overinvestment

This article analyses the implications of the massive increase in AI model training driven by [surging demand for GPUs.](https://www.sequoiacap.com/article/follow-the-gpus-perspective/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=sequoia-implications-of-gpu-overinvestment) The GPU and data center overbuilding will likely \*\*waste capital in the short term but lower costs long-term,\*\*enabling more experimentation. However, startups must shift focus from infrastructure to concrete use cases.

## What's going on here?

There is a disconnect between the AI hype fueling infrastructure overbuilding and the actual end-customer value creation needed to justify it.

![](https://media.beehiiv.com/cdn-cgi/image/fit=scale-down,format=auto,onerror=redirect,quality=80/uploads/asset/file/c5ab5d5d-78d9-443c-8e48-5ca1954dc2ed/image.png)

[Credits: Sequoia Capital](https://www.sequoiacap.com/article/follow-the-gpus-perspective/?utm_source=bensbites\&utm_medium=referral\&utm_campaign=sequoia-implications-of-gpu-overinvestment)

## What does this mean?

Based on a conservative estimate of Nvidia guiding $50B in GPU revenue, $100B will be spent on data centres annually. For investors to earn a return, $200B in value must be created by AI products leveraging these GPUs. But current known revenue from major tech companies utilizing AI is only around $75B, leaving a $125B+ gap.

## Why should I care?

The infrastructure will most likely get cheap with time. Startups need to understand the implications of GPU overinvestment versus end-user value creation and find a balance that works for them and investors. One path forward is to identify specific customer pain points and build narrowly focused AI solutions, rather than building general-purpose LLMs.
